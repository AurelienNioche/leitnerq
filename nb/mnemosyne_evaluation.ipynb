{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lentil import evaluate\n",
    "from lentil import models\n",
    "\n",
    "import mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('savefig', dpi=300)\n",
    "mpl.rc('text', usetex=True)\n",
    "mpl.rc('text.latex', preamble='\\usepackage{amsfonts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'dutch_big_history.pkl'), 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build content features for `mnemosyne_v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'content_features.pkl'), 'rb') as f:\n",
    "    contents_of_item_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_features = {k: (len(f) if f is not None else len(b)) for k, (b, f) in contents_of_item_id.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build content features for `dutch_big`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'original_of_module_id.pkl'), 'rb') as f:\n",
    "    original_of_module_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_of_word = {}\n",
    "with open(os.path.join('data', 'embeddings', 'cbow', 'size=50.embeddings'), 'rb') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split(' ')\n",
    "        embedding_of_word[fields[0]] = np.array([float(x) for x in fields[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_of_word = {}\n",
    "with open(os.path.join('data', 'embeddings', 'cbow', 'unigram_frequencies'), 'rb') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split(' ')\n",
    "        count_of_word[fields[0]] = int(fields[1])\n",
    "total_count = sum(count_of_word.itervalues())\n",
    "freq_of_word = {k: (v / total_count) for k, v in count_of_word.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_features = {k: np.append(\n",
    "        embedding_of_word[original_of_module_id[k]], \n",
    "        [len(original_of_module_id[k]), freq_of_word[original_of_module_id[k]]]) \\\n",
    "                    for k in history.data['module_id'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_features = {k: np.array(\n",
    "        [len(original_of_module_id[k]), freq_of_word[original_of_module_id[k]]]) \\\n",
    "                    for k in history.data['module_id'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_features = {k: np.array(\n",
    "        [len(original_of_module_id[k])]) \\\n",
    "                    for k in history.data['module_id'].unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the IRT benchmark models and memory models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_1pl_irt_model(history, filtered_history, split_history=None):\n",
    "    model = models.OneParameterLogisticModel(\n",
    "        filtered_history, select_regularization_constant=True, name_of_user_id='user_id')\n",
    "    model.fit()\n",
    "    return model\n",
    "\n",
    "def build_2pl_irt_model(history, filtered_history, split_history=None):\n",
    "    model = models.TwoParameterLogisticModel(\n",
    "        filtered_history, select_regularization_constant=True, name_of_user_id='user_id')\n",
    "    model.fit()\n",
    "    return model\n",
    "\n",
    "def build_student_biased_coin_model(history, filtered_history, split_history=None):\n",
    "    model = models.StudentBiasedCoinModel(history, filtered_history, name_of_user_id='user_id')\n",
    "    model.fit()\n",
    "    return model\n",
    "\n",
    "def build_assessment_biased_coin_model(history, filtered_history, split_history=None):\n",
    "    model = models.AssessmentBiasedCoinModel(history, filtered_history)\n",
    "    model.fit()\n",
    "    return model\n",
    "\n",
    "def meta_build_efc_model(\n",
    "    strength_model='deck', using_delay=True, \n",
    "    using_global_difficulty=True, debug_mode_on=True, content_features=None,\n",
    "    coeffs_regularization_constant=1e-6, item_bias_regularization_constant=1e-6,\n",
    "    using_item_bias=True):\n",
    "    def build_efc_model(history, filtered_history, split_history=None):\n",
    "        model = mem.EFCModel(\n",
    "            filtered_history, strength_model=strength_model, using_delay=using_delay, \n",
    "            using_global_difficulty=using_global_difficulty, debug_mode_on=debug_mode_on,\n",
    "            content_features=content_features, using_item_bias=using_item_bias)\n",
    "        model.fit(\n",
    "            learning_rate=0.1, \n",
    "            #learning_rate=(1 if not using_global_difficulty else 0.1), \n",
    "            ftol=1e-6, max_iter=10000,\n",
    "            coeffs_regularization_constant=coeffs_regularization_constant, \n",
    "            item_bias_regularization_constant=item_bias_regularization_constant)\n",
    "        return model\n",
    "    return build_efc_model\n",
    "\n",
    "def meta_build_logistic_regression_model(C=1.0):\n",
    "    def build_logistic_regression_model(history, filtered_history, split_history=None):\n",
    "        model = mem.LogisticRegressionModel(filtered_history)\n",
    "        model.fit(C=C)\n",
    "        return model\n",
    "    return build_logistic_regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_builders = {\n",
    "    '1PL IRT' : build_1pl_irt_model,\n",
    "    'EFC I/-/-' : meta_build_efc_model(\n",
    "        strength_model='deck', using_delay=True, using_global_difficulty=False,\n",
    "        content_features=None, using_item_bias=True, \n",
    "        item_bias_regularization_constant=1e-3),\n",
    "    'EFC I/G/-' : meta_build_efc_model(\n",
    "        strength_model='deck', using_delay=True, using_global_difficulty=True,\n",
    "        content_features=None, using_item_bias=True,\n",
    "        item_bias_regularization_constant=1e-3, coeffs_regularization_constant=1e-3),\n",
    "    'EFC I/G/B' : meta_build_efc_model(\n",
    "        strength_model='deck', using_delay=True, using_global_difficulty=True,\n",
    "        content_features=content_features, using_item_bias=True,\n",
    "        item_bias_regularization_constant=1e-3, coeffs_regularization_constant=1e-3),\n",
    "    'EFC -/G/B' : meta_build_efc_model(\n",
    "        strength_model='deck', using_delay=True, using_global_difficulty=True,\n",
    "        content_features=content_features, using_item_bias=False,\n",
    "        coeffs_regularization_constant=1e-3),\n",
    "    'EFC -/-/B' : meta_build_efc_model(\n",
    "        strength_model='deck', using_delay=True, using_global_difficulty=False,\n",
    "        content_features=content_features, using_item_bias=False,\n",
    "        coeffs_regularization_constant=1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Number of models = %d\" % (len(model_builders))\n",
    "print '\\n'.join(model_builders.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = evaluate.cross_validated_auc(\n",
    "    model_builders,\n",
    "    history,\n",
    "    num_folds=10,\n",
    "    random_truncations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dump results to file\n",
    "with open(os.path.join('results', 'dutch_big_lesion_analysis.pkl'), 'wb') as f:\n",
    "    pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load results from file, replacing current results\n",
    "with open(os.path.join('results', 'dutch_big_lesion_analysis.pkl'), 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = history.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute validation AUCs for separate bins of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_auc(y_trues, probas_pred):\n",
    "    try:\n",
    "        y_trues, probas_pred = zip(*[(y, p) for y, p in zip(y_trues, probas_pred) if not np.isnan(p)])\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_trues, probas_pred, pos_label=1)\n",
    "        return metrics.auc(fpr, tpr)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndata_in_logs = [df['module_id'].ix[idxes].value_counts() for idxes, y_trues, probas_pred in results.train_ixn_data]\n",
    "ndata_of_val_ixns = [df['module_id'].ix[idxes].apply(lambda x: vc.get(x, 0)) for vc, (idxes, y_trues, probas_pred) in zip(ndata_in_logs, results.val_ixn_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_bins = 5\n",
    "hist, bin_edges = np.histogram([y for x in ndata_of_val_ixns for y in x], bins=num_bins)\n",
    "t = [(x+y)/2 for x, y in zip(bin_edges[:-1], bin_edges[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    '1PL IRT',\n",
    "    'EFC I/-/-',\n",
    "    'EFC I/G/-',\n",
    "    'EFC I/G/B',\n",
    "    'EFC -/G/B',\n",
    "    'EFC -/-/B']\n",
    "    \n",
    "model_labels = [\n",
    "    '1PL IRT', \n",
    "    r'$\\gamma_i$',\n",
    "    r'$\\gamma_i + \\beta_0$',\n",
    "    r'$\\gamma_i + \\beta_0 + \\vec{\\beta}_{1:n} \\cdot \\vec{x}_i$',\n",
    "    r'$\\beta_0 + \\vec{\\beta}_{1:n} \\cdot \\vec{x}_i$',\n",
    "    r'$\\vec{\\beta}_{1:n} \\cdot \\vec{x}_i$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel(r'$\\log{(\\theta_i)}$')\n",
    "plt.boxplot([results.validation_aucs(m) for m in model_names])\n",
    "plt.scatter(\n",
    "    range(1, len(model_names) + 1),\n",
    "    [results.test_auc(m) for m in model_names],\n",
    "    color='orange', s=100)\n",
    "\n",
    "plt.xticks(\n",
    "    range(1, len(model_names) + 1), \n",
    "    model_labels, rotation=15)\n",
    "plt.xlim([0.5, len(model_names) + .5])\n",
    "\n",
    "orange_circle = mlines.Line2D([], [], color='orange', marker='o', label='Test')\n",
    "red_line = mlines.Line2D([], [], color='red', marker='_', label='Validation')\n",
    "plt.legend(handles=[red_line, orange_circle], loc='best')\n",
    "\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "plt.savefig(os.path.join('figures', 'dutch_big', 'auc-box-plots-efc-cgi.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_of_m = dict(zip(model_names, model_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_of_model = {}\n",
    "for m in model_names:\n",
    "    s_of_model[m] = [[compute_auc(\n",
    "                [p for p, q in zip(y_trues, vf) if q>=x and (q<y or (bidx==len(bin_edges)-2 and q==y))], \n",
    "                [p for p, q in zip(probas_pred[m], vf) if q>=x and (q<y or (bidx==len(bin_edges)-2 and q==y))]) \\\n",
    "                              for (_, y_trues, probas_pred), vf in zip(results.val_ixn_data, ndata_of_val_ixns)] \\\n",
    "                             for bidx, (x, y) in enumerate(zip(bin_edges[:-1], bin_edges[1:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "sns.set_style('dark')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(bin_edges[:-1], hist, [y-x for x, y in zip(bin_edges[:-1], bin_edges[1:])], color='gray', alpha=0.5, linewidth=0)\n",
    "ax2.set_ylabel('Frequency (number of interactions)')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "lines = []\n",
    "for m, s1 in s_of_model.iteritems():\n",
    "    l1 = ax1.errorbar(\n",
    "        t, [np.nanmean(z) for z in s1], label='%s' % label_of_m[m], \n",
    "        yerr=[np.nanstd(z)/np.sqrt(len(z)) for z in s1])\n",
    "    lines.append(l1)\n",
    "ax1.set_xlabel('Number of training logs for item')\n",
    "ax1.set_ylabel('Validation AUC')\n",
    "\n",
    "first_legend = plt.legend(handles=lines[:3], loc='lower center', bbox_to_anchor=(0.25, -0.4))\n",
    "plt.gca().add_artist(first_legend)\n",
    "plt.legend(handles=lines[3:], loc='lower center', bbox_to_anchor=(0.75, -0.4))\n",
    "\n",
    "plt.savefig(os.path.join('figures', 'dutch_big', 'auc-vs-ndata.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
