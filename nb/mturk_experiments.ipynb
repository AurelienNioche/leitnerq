{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('savefig', dpi=200)\n",
    "mpl.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the log data from the Mechanical Turk experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(os.path.join('data', 'dataset_leitner.dump'), 'rb') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_decks = 5\n",
    "session_duration = 15 * 60 # 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_err = lambda x: np.nanstd(x) / np.sqrt(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort('card_time', inplace=True) # sort in chronological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['worker_id'].apply(lambda x: 'IGOR' not in x)] # filter out artifacts from platform debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['user_id'] = df['worker_id'] # a 'user' can have multiple sessions\n",
    "df['worker_id'] = df['worker_id'] + df['vocab'] # a 'worker' exists for a single session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deck = num_decks corresponds to a new item (i.e., deck = 0) for sessions other than those for vocab.list.japanese.0\n",
    "# don't need to take the deck column too seriously, since we re-compute decks for important analysis\n",
    "df['deck'] = df.apply(lambda row: 0 if row['deck'] == num_decks and row['vocab'] != 'vocab.list.japanese.0' else row['deck'], axis=1)\n",
    "df['deck'] = df['deck'] + 1 # shift decks from [0, num_decks-1] to [1, num_decks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nreps = []\n",
    "delay = []\n",
    "user_items = (df['worker_id'] + '-' + df['foreign']).unique()\n",
    "nreps_of_user_item = {k: 0 for k in user_items}\n",
    "prev_timestamp_of_user_item = {k: np.nan for k in user_items}\n",
    "for _, ixn in df.iterrows():\n",
    "    user_item = ixn['worker_id'] + '-' + ixn['foreign']\n",
    "    timestamp = ixn['card_time']\n",
    "    \n",
    "    nreps.append(nreps_of_user_item[user_item])\n",
    "    delay.append(timestamp - prev_timestamp_of_user_item[user_item])\n",
    "\n",
    "    nreps_of_user_item[user_item] += 1\n",
    "    prev_timestamp_of_user_item[user_item] = timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['nreps'] = nreps # number of repetitions for user-item pair\n",
    "df['delay'] = delay # time elapsed (milliseconds) since previous review for user-item pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['outcome'] = df['score'].apply(lambda x: 0 if x<=2 else 1) # discretize scores into binary outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract assigned arrival rate for each interaction\n",
    "arrival_rate = []\n",
    "for _, row in df.iterrows():\n",
    "    ar = np.nan\n",
    "    if not np.isnan(row['rate']):\n",
    "        ar = row['rate']\n",
    "    elif type(row['probs']) == list:\n",
    "        ar = row['probs'][-1]\n",
    "    arrival_rate.append(ar)\n",
    "df['arrival_rate'] = arrival_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how much data is there for each experimental condition?\n",
    "df['arrival_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute basic stats summarizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_items_per_session = []\n",
    "recall_rates = []\n",
    "session_lengths = []\n",
    "for _, group in df.groupby('worker_id'):\n",
    "    num_items_per_session.append(len(group['foreign'].unique()))\n",
    "    recall_rates.append(np.mean(group['outcome']))\n",
    "    session_lengths.append(len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Number of interactions = %d\" % len(df)\n",
    "print \"Number of users = %d\" % len(df['user_id'].unique())\n",
    "print \"Number of items = %d\" % len(df['foreign'].unique())\n",
    "print \"Number of sessions = %d\" % len(df['worker_id'].unique())\n",
    "print \"Overall recall rate = %0.3f\" % np.mean(df['outcome'])\n",
    "print \"Average number of interactions in session = %0.3f\" % np.mean(session_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(num_items_per_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of Unique Items Seen During Session')\n",
    "plt.ylabel('Frequency (Number of Sessions)')\n",
    "plt.hist(num_items_per_session)\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'num-unique-items-seen-per-session.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimate of the empirical review frequency budget $U$ is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.array(session_lengths) / session_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('log10(Number of Interactions In Session)')\n",
    "plt.ylabel('Frequency (Number of Sessions)')\n",
    "plt.hist(np.log10(np.array(session_lengths)+1))\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'num-ixns-per-session.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_sessions_per_person = []\n",
    "for _, group in df.groupby('user_id'):\n",
    "    num_sessions_per_person.append(len(group['vocab'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(num_sessions_per_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of Sessions')\n",
    "plt.ylabel('Frequency (Number of Users)')\n",
    "plt.hist(num_sessions_per_person)\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'num-sessions-per-person.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decks = range(1, 1 + num_decks)\n",
    "outcomes = [None] * num_decks\n",
    "for deck, group in df[~np.isnan(df['deck'])].groupby('deck'):\n",
    "    if deck <= num_decks:\n",
    "        outcomes[int(deck) - 1] = group['outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Deck')\n",
    "plt.ylabel('Empirical Recall Rate')\n",
    "plt.errorbar(decks, [np.nanmean(x) for x in outcomes], yerr=[std_err(x) for x in outcomes])\n",
    "plt.xticks(decks)\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'recall-rate-vs-deck.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nreps = range(max(df['nreps']) + 1)\n",
    "outcomes = [df[df['nreps']==x]['outcome'].values for x in nreps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Number of repetitions')\n",
    "plt.ylabel('Empirical Recall Rate')\n",
    "plt.errorbar(nreps, [np.nanmean(x) for x in outcomes], yerr=[std_err(x) for x in outcomes])\n",
    "plt.xscale('log')\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'recall-rate-vs-nreps.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delay_ticks = np.arange(0, 6.5, 0.1)\n",
    "recall_rates = []\n",
    "for x, y in zip(delay_ticks[:-1], delay_ticks[1:]):\n",
    "    recall_rates.append(df[df['delay'].apply(lambda z: z > 0 and np.log10(1+z) >= x and np.log10(1+z) < y)]['outcome'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('log10(Delay) (log10-milliseconds)')\n",
    "plt.ylabel('Empirical Recall Rate')\n",
    "plt.errorbar([(x+y)/2 for x, y in zip(delay_ticks[:-1], delay_ticks[1:])], [np.mean(x) for x in recall_rates], yerr=[std_err(x) for x in recall_rates])\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'recall-rate-vs-delay.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('log10(Delay) (log10-milliseconds)')\n",
    "plt.ylabel('Normalized Frequency (Fraction of Total Interactions)')\n",
    "\n",
    "x = np.array(df[df['outcome']==0]['delay'].values)\n",
    "x = x[(~np.isnan(x)) & (x>0)]\n",
    "plt.hist(np.log10(1+x), alpha=0.5, label='forgotten', normed=True, linewidth=0)#, bins=20)\n",
    "\n",
    "x = np.array(df[df['outcome']==1]['delay'].values)\n",
    "x = x[(~np.isnan(x)) & (x>0)]\n",
    "plt.hist(np.log10(1+x), alpha=0.5, label='recalled', normed=True, linewidth=0)#, bins=20)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'delays-cond-outcomes.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr = []\n",
    "for _, group in df.groupby('user_id'):\n",
    "    vc = group['score'].value_counts()\n",
    "    fpr.append(1 - ((1 + vc.get(0, 0)) / (2 + vc.get(0, 0) + vc.get(1, 0) + vc.get(2, 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel('Frequency (Number of Users)')\n",
    "plt.title('Know Thyself, Turker!')\n",
    "plt.hist(fpr, bins=20)\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'know-thyself-fpr.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Recall Rate')\n",
    "plt.ylabel('Frequency (Number of Sessions)')\n",
    "plt.hist(df.groupby('worker_id')['outcome'].mean().values)#, bins=20)\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'user-recall-rates.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('foreign')['outcome'].mean().sort(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Recall Rate')\n",
    "plt.ylabel('Frequency (Number of Items)')\n",
    "plt.hist(df.groupby('foreign')['outcome'].mean().values)#, bins=20)\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'item-recall-rates.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_fit = df[~np.isnan(df['delay'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays = np.array(df_fit['delay'].values) / 1000 # seconds\n",
    "decks = np.array(df_fit['deck'])\n",
    "nreps = np.array(df_fit['nreps']) + 1\n",
    "outcomes = np.array(df_fit['outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thetas = np.arange(0.0072, 0.0082, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lls = []\n",
    "for theta in thetas:\n",
    "    ll_pass = -theta * delays / decks\n",
    "    ll_fail = np.log(1 - np.exp(-theta * delays / decks))\n",
    "    ll = outcomes * ll_pass + (1 - outcomes) * ll_fail\n",
    "    lls.append(np.nansum(ll[np.isfinite(ll)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lls = np.array(lls)\n",
    "marginal_lik = misc.logsumexp(lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posteriors = np.exp(lls - marginal_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel(r'Item Difficulty $\\theta$')\n",
    "plt.ylabel(r'Posterior Probability $P(\\theta \\mid D)$')\n",
    "plt.plot(thetas, posteriors)\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'item-difficulty-posterior.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our maximum-likelihood estimate of the global item difficulty $\\theta$ is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thetas[max(range(len(thetas)), key=lambda x: lls[x])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine phase transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrival_rate = []\n",
    "final_deck_distrn = []\n",
    "num_mastered = []\n",
    "for worker_id, group in df.groupby('worker_id'):\n",
    "    try:\n",
    "        vx = int(100 * group['arrival_rate'].values[-1]) / 100 # handle weird rounding issues\n",
    "        \n",
    "        # re-compute the 'deck' column\n",
    "        deck_of_item = {k: 0 for k in group['foreign'].unique()}\n",
    "        for _, ixn in group.iterrows():\n",
    "            item = ixn['foreign']\n",
    "            outcome = ixn['outcome']\n",
    "            if outcome == 1:\n",
    "                deck_of_item[item] += 1\n",
    "            elif outcome == 0 and deck_of_item[item] > 0:\n",
    "                deck_of_item[item] -= 1\n",
    "        items_of_deck = defaultdict(set)\n",
    "        for k, v in deck_of_item.iteritems():\n",
    "            items_of_deck[min(v, num_decks)] |= {k}\n",
    "        vy = [len(items_of_deck[x]) for x in xrange(num_decks + 1)]\n",
    "        \n",
    "        vz = vy[-1]\n",
    "        arrival_rate.append(vx)\n",
    "        final_deck_distrn.append(vy)\n",
    "        num_mastered.append(vz)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_arrival_rates = sorted(set(arrival_rate))\n",
    "num_mastered_of_arrival_rate = {k: [] for k in unique_arrival_rates}\n",
    "final_deck_distrn_of_arrival_rate = {k: [] for k in unique_arrival_rates}\n",
    "for x, y, z in zip(arrival_rate, num_mastered, final_deck_distrn):\n",
    "    num_mastered_of_arrival_rate[x].append(y)\n",
    "    final_deck_distrn_of_arrival_rate[x].append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_arrival_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale arrival rates from probabilities to proper 'rates' (i.e., having units 'items per second')\n",
    "scaled_unique_arrival_rates = np.array(unique_arrival_rates) * np.mean(session_lengths) / session_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_unique_arrival_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('results', 'theoretical-vs-simulated-phase-transition.pkl'), 'rb') as f:\n",
    "    simulated_arrival_rates, simulated_throughputs, theoretical_phase_transition_threshold = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel(r'Arrival Rate $\\lambda_{ext}$ (Items Per Second)')\n",
    "plt.ylabel(r'Throughput $\\lambda_n$ (Items Per Second)')\n",
    "plt.errorbar(\n",
    "    scaled_unique_arrival_rates[:-1],\n",
    "    [np.mean(np.array(num_mastered_of_arrival_rate[x]) / (15 * 60)) for x in unique_arrival_rates[:-1]],\n",
    "    yerr=[std_err(np.array(num_mastered_of_arrival_rate[x]) / (15 * 60)) for x in unique_arrival_rates[:-1]],\n",
    "    label='Empirical', color='orange')\n",
    "plt.errorbar(simulated_arrival_rates, [np.mean(y) for y in simulated_throughputs], yerr=[std_err(y) for y in simulated_throughputs], label='Simulated (Clocked Delay)', color='green')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'empirical-and-simulated-throughput-vs-arrival-rate.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel(r'Arrival Rate $\\lambda_{ext}$ (Items Per Second)')\n",
    "plt.ylabel(r'Throughput $\\lambda_n$ (Items Per Second)')\n",
    "plt.errorbar(\n",
    "    scaled_unique_arrival_rates[:-1],\n",
    "    [np.mean(np.array(num_mastered_of_arrival_rate[x]) / (15 * 60)) for x in unique_arrival_rates[:-1]],\n",
    "    yerr=[std_err(np.array(num_mastered_of_arrival_rate[x]) / (15 * 60)) for x in unique_arrival_rates[:-1]],\n",
    "    label='Empirical', color='orange')\n",
    "plt.errorbar(simulated_arrival_rates, [np.mean(y) for y in simulated_throughputs], yerr=[std_err(y) for y in simulated_throughputs], label='Simulated (Clocked Delay)', color='green')\n",
    "plt.axvline(x=theoretical_phase_transition_threshold, label='Phase Transition Threshold (Theoretical)', linestyle='--')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'empirical-and-simulated-and-theoretical-throughput-vs-arrival-rate.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Arrival Rate $\\lambda_{ext}$ (Items Per Second)')\n",
    "plt.ylabel('Number of Items')\n",
    "deck_distrns = [[[] for _ in unique_arrival_rates[:-1]] for _ in xrange(num_decks + 1)]\n",
    "for i, x in enumerate(unique_arrival_rates[:-1]):\n",
    "    for deck_distrn in final_deck_distrn_of_arrival_rate[x]:\n",
    "        y = np.array(deck_distrn, dtype=float)\n",
    "        for j, z in enumerate(y):\n",
    "            deck_distrns[j][i].append(z)\n",
    "\n",
    "for i, dd in enumerate(deck_distrns):\n",
    "    label = 'Deck %d' % (i+1)\n",
    "    if i == num_decks:\n",
    "        label = 'Mastered'\n",
    "    plt.errorbar(scaled_unique_arrival_rates[:-1], [np.mean(x) for x in dd], yerr=[std_err(x) for x in dd], label=label)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'num-items-vs-arrival-rate-cond-deck.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Arrival Rate $\\lambda_{ext}$ (Items Per Second)')\n",
    "plt.ylabel('Fraction of Items Seen During Session')\n",
    "deck_distrns = [[[] for _ in unique_arrival_rates[:-1]] for _ in xrange(num_decks + 1)]\n",
    "for i, x in enumerate(unique_arrival_rates[:-1]):\n",
    "    for deck_distrn in final_deck_distrn_of_arrival_rate[x]:\n",
    "        y = np.array(deck_distrn, dtype=float)\n",
    "        y /= y.sum()\n",
    "        for j, z in enumerate(y):\n",
    "            deck_distrns[j][i].append(z)\n",
    "\n",
    "for i, dd in enumerate(deck_distrns):\n",
    "    label = 'Deck %d' % (i+1)\n",
    "    if i == num_decks:\n",
    "        label = 'Mastered'\n",
    "    plt.errorbar(scaled_unique_arrival_rates[:-1], [np.mean(x) for x in dd], yerr=[std_err(x) for x in dd], label=label)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'frac-items-vs-arrival-rate-cond-deck.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Deck')\n",
    "plt.ylabel('Fraction of Items Seen During Session')\n",
    "colors = [None] * len(unique_arrival_rates[:-1])\n",
    "colors[1] = 'red'\n",
    "colors[3] = 'orange'\n",
    "colors[7] = 'deepskyblue'\n",
    "colors[10] = 'blue'\n",
    "for i, (x, z) in enumerate(zip(unique_arrival_rates[:-1], scaled_unique_arrival_rates[:-1])):\n",
    "    if not i in [1, 3, 7, 10]: # cherry-picked\n",
    "        continue\n",
    "    deck_distrns = [[] for _ in xrange(num_decks + 1)]\n",
    "    for deck_distrn in final_deck_distrn_of_arrival_rate[x]:\n",
    "        y = np.array(deck_distrn, dtype=float)\n",
    "        y /= y.sum()\n",
    "        for j, w in enumerate(y):\n",
    "            deck_distrns[j].append(w)\n",
    "\n",
    "    plt.errorbar(\n",
    "        range(1, len(deck_distrns) + 1), [np.mean(x) for x in deck_distrns], \n",
    "        yerr=[std_err(x) for x in deck_distrns], label=r'$\\lambda_{ext} = %0.3f$ (%s Phase Transition)' % (z, 'Before' if i <= 3 else 'After'),\n",
    "        color=colors[i])\n",
    "plt.xlim([0.5, num_decks + 1.5])\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join('figures', 'mturk', 'frac-items-vs-deck-cond-arrival-rate.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
